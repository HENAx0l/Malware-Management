from collections import deque
from collections import OrderedDict 

import random
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.checkpoint import checkpoint
from secml.array import CArray
from secml_malware.models.basee2e import End2EndModel

from secml.settings import SECML_PYTORCH_USE_CUDA

use_cuda = torch.cuda.is_available() and SECML_PYTORCH_USE_CUDA

from attack_space_management import Management

def getParams():
    #Format for this is to make it work easily with Optuna in an automated fashion.
    #variable name -> tuple(sampling function, dict(sampling_args) )
    params = {
        'channels'     : ("suggest_int", {'name':'channels', 'low':32, 'high':1024}),
        'log_stride'   : ("suggest_int", {'name':'log2_stride', 'low':2, 'high':9}),
        'window_size'  : ("suggest_int", {'name':'window_size', 'low':32, 'high':512}),
        'embd_size'    : ("suggest_int", {'name':'embd_size', 'low':4, 'high':64}),
    }
    return OrderedDict(sorted(params.items(), key=lambda t: t[0]))

def initModel(**kwargs):
    new_args = {}
    for x in getParams():
        if x in kwargs:
            new_args[x] = kwargs[x]
            
    return MalConv(**new_args)


class MalConv(End2EndModel):
    
    def __init__(self, out_size=2, channels=128, window_size=512, stride=512, embd_size=8, log_stride=None,mode='default'):
        super(MalConv, self).__init__(embedding_size=embd_size,max_input_size=2**21,embedding_value=256,shift_values=False)
        self.embd = nn.Embedding(257, embd_size, padding_idx=0)
        if not log_stride is None:
            stride = 2**log_stride
        self.mode=mode
        self.conv_1 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)
        self.conv_2 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)

        
        self.fc_1 = nn.Linear(channels, channels)
        self.fc_2 = nn.Linear(channels, out_size)
        
    def filemanage(self,input_x):
        if isinstance(input_x, torch.Tensor):
            inner_array = input_x.squeeze().cpu().numpy()
        else:
            inner_array=input_x
        pebyte = (inner_array[inner_array != 256]).astype(np.uint8).tobytes()
        if self.mode=='default':
            x=pebyte
        else:
            m=Management(pebyte)
            m.scan()
            x=m.bytearray_management(self.mode)
            
        x = np.frombuffer(x[:self.max_input_size], dtype=np.uint8).astype(np.int32)+1
        x=np.pad(x, (0, self.max_input_size - len(x)), constant_values=1)
        x = torch.from_numpy(x).type(torch.LongTensor).unsqueeze(0)
        if use_cuda:
            x = x.cuda()
        return x

    def embed(self, input_x, transpose=True):
        x=self.filemanage(input_x)
        emb_x = self.embd(x)
        if transpose:
            emb_x = torch.transpose(emb_x, 1, 2)
        return emb_x
    
    def embedd_and_forward(self, x):
        conv1d_1 = self.conv_1(x)
        conv1d_2 = self.conv_2(x)
        conv1d_1_activation = torch.relu(conv1d_1)
        conv1d_2_activation = torch.sigmoid(conv1d_2)
        multiply_1 = conv1d_1_activation * conv1d_2_activation
        global_max_pooling1d_1 = F.max_pool1d(input=multiply_1, kernel_size=multiply_1.size()[2:])
        global_max_pooling1d_1_flatten = global_max_pooling1d_1.view(global_max_pooling1d_1.size(0), -1)
        dense_1 = self.fc_1(global_max_pooling1d_1_flatten)
        dense_1_activation = torch.relu(dense_1)
        dense_2 = self.fc_2(dense_1_activation)
        dense_2_activation = torch.sigmoid(dense_2)
        return dense_2_activation[0, 1].unsqueeze(0).unsqueeze(0)
    
    


